{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dota 2: Win Probability Prediction\n",
    "https://www.kaggle.com/c/dota-2-win-probability-prediction/discussion\n",
    "<br>\n",
    "https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/peer/J1SH8/proiekt-priedskazaniia-pobieditielia-v-onlain-ighrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dowlnoading data for train and data for test and selecting a target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('features.csv', index_col='match_id')\n",
    "y_train = X_train.radiant_win\n",
    "X_test = pd.read_csv('features_test.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting of features that are not about the first 5 mins so they can impact on the result since they know the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['duration', 'radiant_win', 'tower_status_radiant',\n",
    "           'tower_status_dire', 'barracks_status_radiant','barracks_status_dire'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Логистическая регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missed values with 0.0. It's a good strategy for methods like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(value=0.0, inplace=True)\n",
    "X_test.fillna(value=0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function CrossValLogReg allows to get the best parameter C = $\\frac{1}{\\lambda}$ from the array = {1e-5, 1e-4,..., 10, 100}\n",
    "<br>\n",
    "For small values of C, the regularization strength increases simple models'll be created which underfit the data. For big values of C the other way around. The model is allowed to increase it's complexity, and therefore, overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValLogReg(X, n):\n",
    "    start_time = datetime.datetime.now()\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    logreg = LogisticRegression(penalty='l2', C=n, solver='lbfgs', random_state=42)\n",
    "    quality = cross_val_score(estimator=logreg, X=X, y=y_train, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "    end_time = datetime.datetime.now()\n",
    "    return quality, end_time-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function ScaleData scales the data (train and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScaleData(X_train, X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train_sc = sc.fit_transform(X_train.astype(float))\n",
    "    X_test_sc = sc.transform(X_test.astype(float))\n",
    "    return X_train_sc, X_test_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function PrintScoreTime_C prints scores on cross validation with given C values and time spent for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintScoreTime_C(result_C):\n",
    "    getbest_C = []\n",
    "    for key, val in result_C.items():\n",
    "        getbest_C.append((key, val[0].mean()))\n",
    "        minutes, seconds = divmod(val[1].total_seconds(), 60)\n",
    "        print(\"C: {0:9.5f}, score on cross validation: {1:.10f}, spent time: {2:.0f} mins and {3:4.2f} sec\"\n",
    "              .format(key, val[0].mean(), minutes, seconds))\n",
    "    getbest_C.sort(key=lambda x:x[1], reverse=True)\n",
    "    print(\"\\nBest C: {0} with score: {1}\".format(getbest_C[0][0], getbest_C[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No thinking about a categorical features\n",
    "Just treat them as numerical features.\n",
    "<br>\n",
    "Scale the data and find the best parameter C in this case.\n",
    "Further there'll be attempts to increase score on cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = ScaleData(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_C = np.power(10.0, np.arange(-5, 3))\n",
    "result_C = {}\n",
    "for n in array_C:\n",
    "    result_C[n] = CrossValLogReg(X_train_scaled, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:   0.00001, score on cross validation: 0.6951552810, spent time: 0 mins and 10.34 sec\n",
      "C:   0.00010, score on cross validation: 0.7113523612, spent time: 0 mins and 2.05 sec\n",
      "C:   0.00100, score on cross validation: 0.7163630590, spent time: 0 mins and 3.20 sec\n",
      "C:   0.01000, score on cross validation: 0.7165498862, spent time: 0 mins and 4.44 sec\n",
      "C:   0.10000, score on cross validation: 0.7165269452, spent time: 0 mins and 4.78 sec\n",
      "C:   1.00000, score on cross validation: 0.7165221088, spent time: 0 mins and 4.41 sec\n",
      "C:  10.00000, score on cross validation: 0.7165218906, spent time: 0 mins and 4.42 sec\n",
      "C: 100.00000, score on cross validation: 0.7165218101, spent time: 0 mins and 4.54 sec\n",
      "\n",
      "Best C: 0.01 with score: 0.7165498862352037\n"
     ]
    }
   ],
   "source": [
    "PrintScoreTime_C(result_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete categorical features at all\n",
    "Try to get if scores on cross validation gets better or not not having categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['lobby_type'] + [name for name in X_train.columns if \"hero\" in name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop categorical features and scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nocateg = X_train.copy()\n",
    "X_test_nocateg = X_test.copy()\n",
    "X_train_nocateg.drop(categorical_features, inplace=True, axis=1)\n",
    "X_test_nocateg.drop(categorical_features, inplace=True, axis=1)\n",
    "X_train_nocateg_sc, X_test_nocateg_sc = ScaleData(X_train_nocateg, X_test_nocateg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best parameter C using cross_val_score for the rebuild data not having categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_C = np.power(10.0, np.arange(-5, 3))\n",
    "result_C = {}\n",
    "for n in array_C:\n",
    "    result_C[n] = CrossValLogReg(X_train_nocateg_sc, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:   0.00001, score on cross validation: 0.6950920646, spent time: 0 mins and 1.84 sec\n",
      "C:   0.00010, score on cross validation: 0.7113327497, spent time: 0 mins and 1.91 sec\n",
      "C:   0.00100, score on cross validation: 0.7163758697, spent time: 0 mins and 2.93 sec\n",
      "C:   0.01000, score on cross validation: 0.7165592000, spent time: 0 mins and 4.14 sec\n",
      "C:   0.10000, score on cross validation: 0.7165338145, spent time: 0 mins and 3.92 sec\n",
      "C:   1.00000, score on cross validation: 0.7165303444, spent time: 0 mins and 3.88 sec\n",
      "C:  10.00000, score on cross validation: 0.7165305329, spent time: 0 mins and 3.92 sec\n",
      "C: 100.00000, score on cross validation: 0.7165304164, spent time: 0 mins and 3.94 sec\n",
      "\n",
      "Best C: 0.01 with score: 0.7165592000076536\n"
     ]
    }
   ],
   "source": [
    "PrintScoreTime_C(result_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use little modified one-hot encoding for categorical features\n",
    "Features $r_k hero$ and $d_k hero$, k=1..5, are important because different heroes have different charasteritics and it impacts on the result of the fight so let's use one-hot encoding to try improve scores on cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OHE = X_train.copy()\n",
    "X_test_OHE = X_test.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get how many different id of heroes exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = [name for name in X_train.columns if \"hero\" in name]\n",
    "uniqueId_heroes = np.unique(X_train_OHE[categorical_features])\n",
    "categorical_features += ['lobby_type']\n",
    "len(uniqueId_heroes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode categorical features: $r_k hero$ and $d_k hero$, k=1..5.\n",
    "<br>\n",
    "Process of encoding looks like: $j$ feature is $0$ if $j$-hero didn't take part in the match, $1$ if $j$-hero was a member of Radiant team and -1 if $j$-hero was a member of Dire.\n",
    "<br>\n",
    "Need to find max id of hero (this is $N$) to create appropriate matrixes for encoding described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncodeData(X, typedata):\n",
    "    original_data = X_test if typedata == 'test' else X_train\n",
    "    for i, match_id in enumerate(original_data.index):\n",
    "        for p in range(5):\n",
    "            X[i, original_data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "            X[i, original_data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = max(uniqueId_heroes) \n",
    "X_train_enc = np.zeros((X_train.shape[0], N))\n",
    "X_test_enc = np.zeros((X_test.shape[0], N))\n",
    "\n",
    "X_train_enc = EncodeData(X_train_enc, 'train')\n",
    "X_test_enc = EncodeData(X_test_enc, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get DataFrame of those matrixes (X_train_enc, X_test_enc) and change their index and columns names for fitting with original data. It'll help to understand information inside them better and to concatenate them with original matrixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_hero = {i:i+1 for i in range(N)}\n",
    "\n",
    "row_train = {i:x for i, x in enumerate(X_train_OHE.index)}\n",
    "encoded_heroes_train = pd.DataFrame(X_train_enc).rename(index=row_train, columns=id_hero)\n",
    "\n",
    "row_test = {i:x for i, x in enumerate(X_test_OHE.index)}\n",
    "encoded_heroes_test = pd.DataFrame(X_test_enc).rename(index=row_test, columns=id_hero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OHE_enc = pd.concat([X_train_OHE, encoded_heroes_train], axis=1)\n",
    "X_test_OHE_enc = pd.concat([X_test_OHE, encoded_heroes_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop extra features that were changed using one-hot encoding and scale the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OHE_enc.drop(categorical_features, axis=1, inplace=True)\n",
    "X_test_OHE_enc.drop(categorical_features, axis=1, inplace=True)\n",
    "X_train_OHE_enc_scaled, X_test_OHE_enc_scaled = ScaleData(X_train_OHE_enc, X_test_OHE_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best parameter C using cross_val_score for the new build data (X_train_OHE_enc_scaled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_C = np.power(10.0, np.arange(-5, 3))\n",
    "result_C = {}\n",
    "for n in array_C:\n",
    "    result_C[n] = CrossValLogReg(X_train_OHE_enc_scaled, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:   0.00001, score on cross validation: 0.7147781039, spent time: 0 mins and 4.24 sec\n",
      "C:   0.00010, score on cross validation: 0.7427271252, spent time: 0 mins and 4.27 sec\n",
      "C:   0.00100, score on cross validation: 0.7516116548, spent time: 0 mins and 6.09 sec\n",
      "C:   0.01000, score on cross validation: 0.7519639456, spent time: 0 mins and 8.38 sec\n",
      "C:   0.10000, score on cross validation: 0.7519296127, spent time: 0 mins and 8.99 sec\n",
      "C:   1.00000, score on cross validation: 0.7519244691, spent time: 0 mins and 9.04 sec\n",
      "C:  10.00000, score on cross validation: 0.7519241578, spent time: 0 mins and 8.62 sec\n",
      "C: 100.00000, score on cross validation: 0.7519241366, spent time: 0 mins and 9.41 sec\n",
      "\n",
      "Best C: 0.01 with score: 0.7519639455861148\n"
     ]
    }
   ],
   "source": [
    "PrintScoreTime_C(result_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities on test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the best model in this case is Logistic regression with $C = 0.01$ that was used over the preprocessed data: encoding categorical features of all heroes. So let's just take it and predict probabilities on test sample X_test that was also of course changed in the way like X_train was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8227909  0.75216683 0.18906701 ... 0.2379355  0.6283895  0.42762756]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l2', C=0.01, solver='lbfgs', random_state=42, n_jobs=-1)\n",
    "logreg.fit(X_train_OHE_enc_scaled, y_train)\n",
    "prob_pred = logreg.predict_proba(X_test_OHE_enc_scaled)[:,1]\n",
    "print(prob_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what the best and the worst values were got in prob_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00850599069841149 0.9962795503882215\n"
     ]
    }
   ],
   "source": [
    "print(min(prob_pred), max(prob_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
