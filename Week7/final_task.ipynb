{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dota 2: Win Probability Prediction\n",
    "https://www.kaggle.com/c/dota-2-win-probability-prediction/discussion\n",
    "<br>\n",
    "https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/peer/J1SH8/proiekt-priedskazaniia-pobieditielia-v-onlain-ighrie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dowlnoading data for train and data for test and selecting a target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('features.csv', index_col='match_id')\n",
    "y_train = X_train.radiant_win\n",
    "X_test = pd.read_csv('features_test.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function MissingValuesTable showed how many values are missed in data (that is an object of DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MissingValuesTable(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        by='% of Total Values', ascending=False).round(1)\n",
    "        print (\"Selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There're \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected dataframe has 108 columns.\n",
      "There're 12 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_blood_player2</th>\n",
       "      <td>43987</td>\n",
       "      <td>45.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_flying_courier_time</th>\n",
       "      <td>27479</td>\n",
       "      <td>28.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_flying_courier_time</th>\n",
       "      <td>26098</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_blood_time</th>\n",
       "      <td>19553</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_blood_team</th>\n",
       "      <td>19553</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_blood_player1</th>\n",
       "      <td>19553</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_bottle_time</th>\n",
       "      <td>16143</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_bottle_time</th>\n",
       "      <td>15691</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_first_ward_time</th>\n",
       "      <td>1836</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_first_ward_time</th>\n",
       "      <td>1826</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_courier_time</th>\n",
       "      <td>692</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_courier_time</th>\n",
       "      <td>676</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Missing Values  % of Total Values\n",
       "first_blood_player2                   43987               45.2\n",
       "radiant_flying_courier_time           27479               28.3\n",
       "dire_flying_courier_time              26098               26.8\n",
       "first_blood_time                      19553               20.1\n",
       "first_blood_team                      19553               20.1\n",
       "first_blood_player1                   19553               20.1\n",
       "dire_bottle_time                      16143               16.6\n",
       "radiant_bottle_time                   15691               16.1\n",
       "radiant_first_ward_time                1836                1.9\n",
       "dire_first_ward_time                   1826                1.9\n",
       "radiant_courier_time                    692                0.7\n",
       "dire_courier_time                       676                0.7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MissingValuesTable(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting of features that are not about the first 5 mins so they can impact on the result since they know the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['duration', 'radiant_win', 'tower_status_radiant',\n",
    "           'tower_status_dire', 'barracks_status_radiant','barracks_status_dire'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Gradient Boosting classifier (Градиентный бустинг \"в лоб\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missed values with a huge number.\n",
    "<br>\n",
    "This allows send objects containing missed values to another branch thus classification can be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, fill_value=1e9, strategy='constant')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "#X_train.fillna(value=1e9, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functon CrossValGBC let make cross validation on different count of trees(n_estimators).\n",
    "<br>\n",
    "It returns array of scores after cross_val_score and spent time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValGBC(n):\n",
    "    start_time = datetime.datetime.now()\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, random_state=42)\n",
    "    quality = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "    end_time = datetime.datetime.now()\n",
    "    return quality, end_time-start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test n = {10, 20, 30, 100} and save all in a dictionary where key is $n_i$ and value is a tuple of array of scores and spent time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [10, 20, 30, 100]\n",
    "res = {}\n",
    "for n in n_trees:\n",
    "    res[n] = CrossValGBC(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of trees:  10, score on cross validation: 0.6660340265, spent time: 0 mins and 49.23 sec\n",
      "Count of trees:  20, score on cross validation: 0.6834568680, spent time: 1 mins and 13.86 sec\n",
      "Count of trees:  30, score on cross validation: 0.6899489423, spent time: 1 mins and 46.87 sec\n",
      "Count of trees: 100, score on cross validation: 0.7067004675, spent time: 5 mins and 40.64 sec\n"
     ]
    }
   ],
   "source": [
    "for key, val in res.items():\n",
    "    minutes, seconds = divmod(val[1].total_seconds(), 60)\n",
    "    print(\"Count of trees: {0:3}, score on cross validation: {1:.10f}, spent time:{2:2.0f} mins and {3:.2f} sec\"\n",
    "          .format(key, val[0].mean(), minutes, seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dowlnoading data for train and data for test and selecting a target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('features.csv', index_col='match_id')\n",
    "y_train = X_train.radiant_win\n",
    "X_test = pd.read_csv('features_test.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting of features that are not about the first 5 mins so they can impact on the result since they know the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['duration', 'radiant_win', 'tower_status_radiant',\n",
    "           'tower_status_dire', 'barracks_status_radiant','barracks_status_dire'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Логистическая регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missed values with 0.0. It's a good strategy for methods like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(value=0.0, inplace=True)\n",
    "X_test.fillna(value=0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function CrossValLogReg allows to get the best parameter C = $\\frac{1}{\\lambda}$ from the array = {1e-5, 1e-4,..., 10, 100}\n",
    "<br>\n",
    "For small values of C, the regularization strength increases simple models'll be created which underfit the data. For big values of C the other way around. The model is allowed to increase it's complexity, and therefore, overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValLogReg(X, n):\n",
    "    start_time = datetime.datetime.now()\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    logreg = LogisticRegression(penalty='l2', C=n, solver='lbfgs', random_state=42)\n",
    "    quality = cross_val_score(estimator=logreg, X=X, y=y_train, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "    end_time = datetime.datetime.now()\n",
    "    return quality, end_time-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function ScaleData scales the data (train and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScaleData(X_train, X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train_sc = sc.fit_transform(X_train.astype(float))\n",
    "    X_test_sc = sc.transform(X_test.astype(float))\n",
    "    return X_train_sc, X_test_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function PrintScoreTime_C prints scores on cross validation with given C values and time spent for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintScoreTime_C(result_C):\n",
    "    getbest_C = []\n",
    "    for key, val in result_C.items():\n",
    "        getbest_C.append((key, val[0].mean()))\n",
    "        minutes, seconds = divmod(val[1].total_seconds(), 60)\n",
    "        print(\"C: {0:9.5f}, score on cross validation: {1:.10f}, spent time: {2:.0f} mins and {3:4.2f} sec\"\n",
    "              .format(key, val[0].mean(), minutes, seconds))\n",
    "    getbest_C.sort(key=lambda x:x[1], reverse=True)\n",
    "    print(\"\\nBest C: {0} with score: {1}\".format(getbest_C[0][0], getbest_C[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No thinking about categorical features\n",
    "Just treat them as numerical features.\n",
    "<br>\n",
    "Scale the data and find the best parameter C in this case.\n",
    "Further there'll be attempts to increase score on cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = ScaleData(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_C = np.power(10.0, np.arange(-5, 3))\n",
    "result_C = {}\n",
    "for n in array_C:\n",
    "    result_C[n] = CrossValLogReg(X_train_scaled, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:   0.00001, score on cross validation: 0.6951552810, spent time: 0 mins and 11.07 sec\n",
      "C:   0.00010, score on cross validation: 0.7113523612, spent time: 0 mins and 2.28 sec\n",
      "C:   0.00100, score on cross validation: 0.7163630590, spent time: 0 mins and 3.28 sec\n",
      "C:   0.01000, score on cross validation: 0.7165498862, spent time: 0 mins and 4.32 sec\n",
      "C:   0.10000, score on cross validation: 0.7165269452, spent time: 0 mins and 4.59 sec\n",
      "C:   1.00000, score on cross validation: 0.7165221088, spent time: 0 mins and 4.78 sec\n",
      "C:  10.00000, score on cross validation: 0.7165218906, spent time: 0 mins and 4.51 sec\n",
      "C: 100.00000, score on cross validation: 0.7165218101, spent time: 0 mins and 4.97 sec\n",
      "\n",
      "Best C: 0.01 with score: 0.7165498862352037\n"
     ]
    }
   ],
   "source": [
    "PrintScoreTime_C(result_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete categorical features at all\n",
    "Try to get if scores on cross validation gets better or not not having categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['lobby_type'] + [name for name in X_train.columns if \"hero\" in name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop categorical features and scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nocateg = X_train.copy()\n",
    "X_test_nocateg = X_test.copy()\n",
    "X_train_nocateg.drop(categorical_features, inplace=True, axis=1)\n",
    "X_test_nocateg.drop(categorical_features, inplace=True, axis=1)\n",
    "X_train_nocateg_sc, X_test_nocateg_sc = ScaleData(X_train_nocateg, X_test_nocateg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best parameter C using cross_val_score for the rebuild data not having categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_C = np.power(10.0, np.arange(-5, 3))\n",
    "result_C = {}\n",
    "for n in array_C:\n",
    "    result_C[n] = CrossValLogReg(X_train_nocateg_sc, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:   0.00001, score on cross validation: 0.6950920646, spent time: 0 mins and 2.03 sec\n",
      "C:   0.00010, score on cross validation: 0.7113327497, spent time: 0 mins and 2.32 sec\n",
      "C:   0.00100, score on cross validation: 0.7163758697, spent time: 0 mins and 3.30 sec\n",
      "C:   0.01000, score on cross validation: 0.7165592000, spent time: 0 mins and 3.87 sec\n",
      "C:   0.10000, score on cross validation: 0.7165338145, spent time: 0 mins and 4.00 sec\n",
      "C:   1.00000, score on cross validation: 0.7165303444, spent time: 0 mins and 4.09 sec\n",
      "C:  10.00000, score on cross validation: 0.7165305329, spent time: 0 mins and 3.94 sec\n",
      "C: 100.00000, score on cross validation: 0.7165304164, spent time: 0 mins and 3.96 sec\n",
      "\n",
      "Best C: 0.01 with score: 0.7165592000076536\n"
     ]
    }
   ],
   "source": [
    "PrintScoreTime_C(result_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use little modified one-hot encoding for categorical features\n",
    "Features $r_k hero$ and $d_k hero$, k=1..5, are important because different heroes have different charasteritics and it impacts on the result of the fight so let's use one-hot encoding to try improve scores on cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OHE = X_train.copy()\n",
    "X_test_OHE = X_test.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get how many different id of heroes exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = [name for name in X_train.columns if \"hero\" in name]\n",
    "uniqueId_heroes = np.unique(X_train_OHE[categorical_features])\n",
    "categorical_features += ['lobby_type']\n",
    "len(uniqueId_heroes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode categorical features: $r_k hero$ and $d_k hero$, k=1..5.\n",
    "<br>\n",
    "Process of encoding looks like: $j$ feature is $0$ if $j$-hero didn't take part in the match, $1$ if $j$-hero was a member of Radiant team and -1 if $j$-hero was a member of Dire.\n",
    "<br>\n",
    "Need to find max id of hero (this is $N$) to create appropriate matrixes for encoding described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncodeData(X, typedata):\n",
    "    original_data = X_test if typedata == 'test' else X_train\n",
    "    for i, match_id in enumerate(original_data.index):\n",
    "        for p in range(5):\n",
    "            X[i, original_data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "            X[i, original_data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = max(uniqueId_heroes) \n",
    "X_train_enc = np.zeros((X_train.shape[0], N))\n",
    "X_test_enc = np.zeros((X_test.shape[0], N))\n",
    "\n",
    "X_train_enc = EncodeData(X_train_enc, 'train')\n",
    "X_test_enc = EncodeData(X_test_enc, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get DataFrame of those matrixes (X_train_enc, X_test_enc) and change their index and columns names for fitting with original data. It'll help to understand information inside them better and to concatenate them with original matrixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_hero = {i:i+1 for i in range(N)}\n",
    "\n",
    "row_train = {i:x for i, x in enumerate(X_train_OHE.index)}\n",
    "encoded_heroes_train = pd.DataFrame(X_train_enc).rename(index=row_train, columns=id_hero)\n",
    "\n",
    "row_test = {i:x for i, x in enumerate(X_test_OHE.index)}\n",
    "encoded_heroes_test = pd.DataFrame(X_test_enc).rename(index=row_test, columns=id_hero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OHE_enc = pd.concat([X_train_OHE, encoded_heroes_train], axis=1)\n",
    "X_test_OHE_enc = pd.concat([X_test_OHE, encoded_heroes_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop extra features that were changed using one-hot encoding and scale the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OHE_enc.drop(categorical_features, axis=1, inplace=True)\n",
    "X_test_OHE_enc.drop(categorical_features, axis=1, inplace=True)\n",
    "X_train_OHE_enc_scaled, X_test_OHE_enc_scaled = ScaleData(X_train_OHE_enc, X_test_OHE_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best parameter C using cross_val_score for the new build data (X_train_OHE_enc_scaled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_C = np.power(10.0, np.arange(-5, 3))\n",
    "result_C = {}\n",
    "for n in array_C:\n",
    "    result_C[n] = CrossValLogReg(X_train_OHE_enc_scaled, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:   0.00001, score on cross validation: 0.7147781039, spent time: 0 mins and 13.82 sec\n",
      "C:   0.00010, score on cross validation: 0.7427271252, spent time: 0 mins and 5.19 sec\n",
      "C:   0.00100, score on cross validation: 0.7516116548, spent time: 0 mins and 7.99 sec\n",
      "C:   0.01000, score on cross validation: 0.7519639456, spent time: 0 mins and 10.54 sec\n",
      "C:   0.10000, score on cross validation: 0.7519296127, spent time: 0 mins and 11.37 sec\n",
      "C:   1.00000, score on cross validation: 0.7519244691, spent time: 0 mins and 11.07 sec\n",
      "C:  10.00000, score on cross validation: 0.7519241578, spent time: 0 mins and 10.47 sec\n",
      "C: 100.00000, score on cross validation: 0.7519241366, spent time: 0 mins and 11.82 sec\n",
      "\n",
      "Best C: 0.01 with score: 0.7519639455861148\n"
     ]
    }
   ],
   "source": [
    "PrintScoreTime_C(result_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities on test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the best model in this case is Logistic regression with $C = 0.01$ that was used over the preprocessed data: encoding categorical features of all heroes. So let's just take it and predict probabilities on test sample X_test that was also of course changed in the way like X_train was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8227909  0.75216683 0.18906701 ... 0.2379355  0.6283895  0.42762756]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l2', C=0.01, solver='lbfgs', random_state=42, n_jobs=-1)\n",
    "logreg.fit(X_train_OHE_enc_scaled, y_train)\n",
    "prob_pred = logreg.predict_proba(X_test_OHE_enc_scaled)[:,1]\n",
    "print(prob_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what the best and the worst values were got in prob_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00850599069841149 0.9962795503882215\n"
     ]
    }
   ],
   "source": [
    "print(min(prob_pred), max(prob_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
